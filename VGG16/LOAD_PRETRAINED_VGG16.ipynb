{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFZkqa-K_YPe"
      },
      "source": [
        "# Importing libraries and import MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOZVC8JTrQ1H",
        "outputId": "f053c3e0-b2fe-4664-bf45-43031e15c7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing libraries completed.\n"
          ]
        }
      ],
      "source": [
        "# importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm # for progress bar\n",
        "\n",
        "# Libraries for TensorFlow\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow import keras\n",
        "\n",
        "# Library for Transfer Learning\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "print(\"Importing libraries completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2INU91Grikm",
        "outputId": "6166040a-aca3-4578-edac-fd9e81431e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Loading dataset from keras\n",
        "\n",
        "(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvafgkAYuIXz",
        "outputId": "5142c1e8-4ccc-4686-9cc6-86acdf64369c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Loading dataset from keras\n",
        "\n",
        "(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()\n",
        "print(type(xtrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idYQny5D_glI"
      },
      "source": [
        "# Preprocessing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNFlx8jesvqc",
        "outputId": "cbd17c3d-2b95-4327-fb93-6a4b602067b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 84), (10000, 28, 84))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain=np.dstack([xtrain] * 3)\n",
        "xtest=np.dstack([xtest]*3)\n",
        "xtrain.shape,xtest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdJgYepWvt_Q",
        "outputId": "e3bb1a32-668f-402c-98f6-7bf706f2b9a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain = xtrain.reshape(-1, 28,28,3)\n",
        "xtest= xtest.reshape (-1,28,28,3)\n",
        "xtrain.shape,xtest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MhK1L8_Eurfy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import img_to_array, array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP2uFiZ_uMdv",
        "outputId": "5a023f64-b680-4aee-8c06-58fd407ee9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Resize the images 48*48 as required by VGG16\n",
        "\n",
        "\n",
        "xtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\n",
        "xtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n",
        "\n",
        "xtrain.shape, xtest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Av4w0wO_wNBY"
      },
      "outputs": [],
      "source": [
        "# to store array value of the images\n",
        "x=xtrain\n",
        "# to store the labels of the images\n",
        "y=ytrain\n",
        "\n",
        "test_images=xtest\n",
        "test_images_Original=xtest\n",
        "# to store the labels of the images\n",
        "test_image_label=ytest\n",
        "\n",
        "val_images=xtest\n",
        "val_images_Original=xtest\n",
        "# to store the labels of the images\n",
        "val_image_label=ytest # to store the labels of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcgzevctwinO",
        "outputId": "4beba3cb-9244-4b25-8440-a07a7cf344bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset\n",
            "(60000, 48, 48, 3)\n",
            "(60000, 10)\n",
            "Test Dataset\n",
            "(10000, 48, 48, 3)\n",
            "(10000, 10)\n",
            "Validation Dataset\n",
            "(10000, 48, 48, 3)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training Dataset\n",
        "print(\"Training Dataset\")\n",
        "\n",
        "x=np.array(x) # Converting to np arrary to pass to the model\n",
        "print(x.shape)\n",
        "y=to_categorical(y) # onehot encoding of the labels\n",
        "#print(y)\n",
        "print(y.shape)\n",
        "\n",
        "# Test Dataset\n",
        "print(\"Test Dataset\")\n",
        "\n",
        "test_images=np.array(test_images) \n",
        "print(test_images.shape)\n",
        "\n",
        "test_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\n",
        "print(test_image_label.shape)\n",
        "\n",
        "# Validation Dataset\n",
        "print(\"Validation Dataset\")\n",
        "\n",
        "val_images=np.array(val_images) \n",
        "print(val_images.shape)\n",
        "\n",
        "val_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\n",
        "print(val_image_label.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbuh3rJyNcM",
        "outputId": "6df380f8-5a3d-48ac-d00d-0aa56141f4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6000, 48, 48, 3) (6000, 10)\n",
            "(1000, 48, 48, 3) (1000, 10)\n",
            "(1000, 48, 48, 3) (1000, 10)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = x[:6000,:]\n",
        "y = y[:6000,:]\n",
        "print(x.shape, y.shape)\n",
        "val_images, val_image_label = val_images[:1000,:], val_image_label[:1000,:]\n",
        "print(val_images.shape, val_image_label.shape)\n",
        "test_images, test_image_label = test_images[1000:2000,:], test_image_label[1000:2000,:]\n",
        "print(test_images.shape, test_image_label.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks7tWEcWFh_t"
      },
      "source": [
        "# Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuGQYiWvzY0q",
        "outputId": "e5838518-8fee-4684-a593-612707fbda0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of default VGG16 model.\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 15s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Check properties of the model that we are going to use for Transfer Learning\n",
        "\n",
        "print(\"Summary of default VGG16 model.\\n\")\n",
        "\n",
        "# we are using VGG16 for transfer learnin here. So we have imported it\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# initializing model with weights='imagenet'i.e. we are carring its original weights\n",
        "model_vgg16=VGG16(weights='imagenet')\n",
        "\n",
        "# display the summary to see the properties of the model\n",
        "model_vgg16.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRQJGK0yGCok"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbBI0YnL1gWn",
        "outputId": "37b60b74-fdcd-40d1-d177-2fc68d799396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of Custom VGG16 model.\n",
            "\n",
            "1) We setup input layer and 2) We removed top (last) layer. \n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelling WITH Transfer Learning\n",
        "\n",
        "# Here we will prepare model as per our requirements\n",
        "\n",
        "print(\"Summary of Custom VGG16 model.\\n\")\n",
        "print(\"1) We setup input layer and 2) We removed top (last) layer. \\n\")\n",
        "\n",
        "# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (224,224,3)\n",
        "input_layer=layers.Input(shape=(48,48,3))\n",
        "\n",
        "# initialize the transfer model VGG16 with appropriate properties per our need.\n",
        "# we are passing paramers as following\n",
        "# 1) weights='imagenet' - Using this we are carring weights as of original weights.\n",
        "# 2) input_tensor to pass the VGG16 using input_tensor\n",
        "# 3) we want to change the last layer so we are not including top layer\n",
        "model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n",
        "model_vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roAV7ylN_EHn",
        "outputId": "df3a5d0b-9d90-492d-f3eb-e5a10a306e9b"
      },
      "outputs": [],
      "source": [
        "# access the current last layer of the model and add flatten and dense after it\n",
        "\n",
        "print(\"Summary of Custom VGG16 model.\\n\")\n",
        "\n",
        "last_layer=model_vgg16.output # we are taking last layer of the model\n",
        "\n",
        "# Add flatten layer: we are extending Neural Network by adding flatten layer\n",
        "flatten=layers.Flatten()(last_layer)\n",
        "dropout=layers.Dropout(0.3)(flatten)\n",
        "# Add dense layer\n",
        "dense1=layers.Dense(100,activation='relu')(dropout)\n",
        "\n",
        "# Add dense layer to the final output layer\n",
        "output_layer=layers.Dense(10,activation='softmax')(dense1)\n",
        "\n",
        "# Creating model with input and output layer\n",
        "model=models.Model(inputs=input_layer,outputs=output_layer)\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyokl7WPB5i9",
        "outputId": "300e815e-f150-4eec-b96a-5b37a2ad9b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are making all the layers intrainable except the last layer. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# we will freez all the layers except the last layer\n",
        "\n",
        "# we are making all the layers intrainable except the last 2 layers\n",
        "print(\"We are making all the layers intrainable except the last layer. \\n\")\n",
        "\n",
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable=False\n",
        "\n",
        "model.layers[len(model.layers)-2].trainable = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3WS7cCAGx3E"
      },
      "source": [
        "# Compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CleKGVHTGGdS",
        "outputId": "9b3ebbce-969d-4070-a669-05e79aba2df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compilation completed.\n"
          ]
        }
      ],
      "source": [
        "# Compiling Model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozaJXIiGHheQ"
      },
      "source": [
        "# Evaluation before training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGhu2IF38e",
        "outputId": "b1d8cc70-3aea-422f-acce-5e78530f5178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 9s 21ms/step - loss: 14.0171 - accuracy: 0.1060\n",
            "Test loss:  14.01707649230957\n",
            "Test accuracy:  0.10599999874830246\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_images, test_image_label)\n",
        "print(\"Test loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYOYYu7rHWER"
      },
      "source": [
        "# Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKn0OnF6GOV5",
        "outputId": "fccce9fe-2cbc-4900-e744-dabcc9a6c148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 10s 599ms/step - loss: 11.4862 - accuracy: 0.2335 - val_loss: 3.6622 - val_accuracy: 0.5200\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 2s 153ms/step - loss: 4.7053 - accuracy: 0.4907 - val_loss: 2.2848 - val_accuracy: 0.6480\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 2s 154ms/step - loss: 2.9656 - accuracy: 0.6123 - val_loss: 1.5656 - val_accuracy: 0.7060\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 2s 154ms/step - loss: 2.2631 - accuracy: 0.6658 - val_loss: 1.2800 - val_accuracy: 0.7470\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 2s 155ms/step - loss: 1.8042 - accuracy: 0.6967 - val_loss: 1.1034 - val_accuracy: 0.7680\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 2s 155ms/step - loss: 1.5832 - accuracy: 0.7195 - val_loss: 0.9964 - val_accuracy: 0.7860\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 2s 155ms/step - loss: 1.4358 - accuracy: 0.7353 - val_loss: 0.8829 - val_accuracy: 0.7880\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 2s 155ms/step - loss: 1.2099 - accuracy: 0.7480 - val_loss: 0.8042 - val_accuracy: 0.8150\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 2s 156ms/step - loss: 1.1553 - accuracy: 0.7575 - val_loss: 0.7555 - val_accuracy: 0.8180\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 2s 159ms/step - loss: 1.0757 - accuracy: 0.7675 - val_loss: 0.7139 - val_accuracy: 0.8230\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 2s 160ms/step - loss: 0.9376 - accuracy: 0.7840 - val_loss: 0.6842 - val_accuracy: 0.8310\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 2s 158ms/step - loss: 0.9467 - accuracy: 0.7853 - val_loss: 0.6783 - val_accuracy: 0.8270\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 2s 158ms/step - loss: 0.8847 - accuracy: 0.7935 - val_loss: 0.6741 - val_accuracy: 0.8170\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 2s 158ms/step - loss: 0.8429 - accuracy: 0.7963 - val_loss: 0.6597 - val_accuracy: 0.8200\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 2s 159ms/step - loss: 0.7876 - accuracy: 0.8077 - val_loss: 0.5882 - val_accuracy: 0.8330\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 2s 159ms/step - loss: 0.7689 - accuracy: 0.8112 - val_loss: 0.5771 - val_accuracy: 0.8330\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 2s 161ms/step - loss: 0.7179 - accuracy: 0.8133 - val_loss: 0.5764 - val_accuracy: 0.8350\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 2s 160ms/step - loss: 0.6910 - accuracy: 0.8267 - val_loss: 0.5644 - val_accuracy: 0.8360\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 2s 161ms/step - loss: 0.6547 - accuracy: 0.8222 - val_loss: 0.5447 - val_accuracy: 0.8460\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 2s 161ms/step - loss: 0.6429 - accuracy: 0.8260 - val_loss: 0.5270 - val_accuracy: 0.8460\n",
            "Fitting the model completed.\n"
          ]
        }
      ],
      "source": [
        "# Fit the Model\n",
        "\n",
        "# xtrain2=xtrain.reshape(60000,48,48,3)\n",
        "# xtest2=xtest.reshape(10000,48,48,3)\n",
        "\n",
        "history = model.fit(x,y,epochs=20,batch_size=512,verbose=True,validation_data=(val_images,val_image_label))\n",
        "\n",
        "print(\"Fitting the model completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBYgbV53HdWW"
      },
      "source": [
        "# Evaluation after training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVquerGDHGOl",
        "outputId": "866f2d23-6eaa-4bdb-cc65-c7a49f133bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 13ms/step - loss: 0.5622 - accuracy: 0.8400\n",
            "Test loss:  0.5621785521507263\n",
            "Test accuracy:  0.8399999737739563\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_images, test_image_label)\n",
        "print(\"Test loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
